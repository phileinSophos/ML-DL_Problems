{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the training dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "      <th>Safety_Score</th>\n",
       "      <th>Days_Since_Inspection</th>\n",
       "      <th>Total_Safety_Complaints</th>\n",
       "      <th>Control_Metric</th>\n",
       "      <th>Turbulence_In_gforces</th>\n",
       "      <th>Cabin_Temperature</th>\n",
       "      <th>Accident_Type_Code</th>\n",
       "      <th>Max_Elevation</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Adverse_Weather_Metric</th>\n",
       "      <th>Accident_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>49.223744</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>71.285324</td>\n",
       "      <td>0.272118</td>\n",
       "      <td>78.04</td>\n",
       "      <td>2</td>\n",
       "      <td>31335.476824</td>\n",
       "      <td>3</td>\n",
       "      <td>0.424352</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>62.465753</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>72.288058</td>\n",
       "      <td>0.423939</td>\n",
       "      <td>84.54</td>\n",
       "      <td>2</td>\n",
       "      <td>26024.711057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>12128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Significant_Damage_And_Fatalities</td>\n",
       "      <td>63.059361</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>66.362808</td>\n",
       "      <td>0.322604</td>\n",
       "      <td>78.86</td>\n",
       "      <td>7</td>\n",
       "      <td>39269.053927</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
       "      <td>48.082192</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>74.703737</td>\n",
       "      <td>0.337029</td>\n",
       "      <td>81.79</td>\n",
       "      <td>3</td>\n",
       "      <td>42771.499200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211728</td>\n",
       "      <td>5946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Significant_Damage_And_Fatalities</td>\n",
       "      <td>26.484018</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>47.948952</td>\n",
       "      <td>0.541140</td>\n",
       "      <td>77.16</td>\n",
       "      <td>3</td>\n",
       "      <td>35509.228515</td>\n",
       "      <td>2</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>9054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Severity  Safety_Score  ...  Adverse_Weather_Metric  Accident_ID\n",
       "0                Minor_Damage_And_Injuries     49.223744  ...                0.424352         7570\n",
       "1                Minor_Damage_And_Injuries     62.465753  ...                0.352350        12128\n",
       "2        Significant_Damage_And_Fatalities     63.059361  ...                0.003364         2181\n",
       "3  Significant_Damage_And_Serious_Injuries     48.082192  ...                0.211728         5946\n",
       "4        Significant_Damage_And_Fatalities     26.484018  ...                0.176883         9054\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the target variables to Y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['Severity']\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropoing the irrelevent columns from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Safety_Score</th>\n",
       "      <th>Days_Since_Inspection</th>\n",
       "      <th>Total_Safety_Complaints</th>\n",
       "      <th>Control_Metric</th>\n",
       "      <th>Turbulence_In_gforces</th>\n",
       "      <th>Cabin_Temperature</th>\n",
       "      <th>Max_Elevation</th>\n",
       "      <th>Violations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>49.223744</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>71.285324</td>\n",
       "      <td>0.272118</td>\n",
       "      <td>78.04</td>\n",
       "      <td>31335.476824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>62.465753</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>72.288058</td>\n",
       "      <td>0.423939</td>\n",
       "      <td>84.54</td>\n",
       "      <td>26024.711057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>63.059361</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>66.362808</td>\n",
       "      <td>0.322604</td>\n",
       "      <td>78.86</td>\n",
       "      <td>39269.053927</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48.082192</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>74.703737</td>\n",
       "      <td>0.337029</td>\n",
       "      <td>81.79</td>\n",
       "      <td>42771.499200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26.484018</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>47.948952</td>\n",
       "      <td>0.541140</td>\n",
       "      <td>77.16</td>\n",
       "      <td>35509.228515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Safety_Score  Days_Since_Inspection  Total_Safety_Complaints  ...  Cabin_Temperature  Max_Elevation  Violations\n",
       "0     49.223744                     14                       22  ...              78.04   31335.476824           3\n",
       "1     62.465753                     10                       27  ...              84.54   26024.711057           2\n",
       "2     63.059361                     13                       16  ...              78.86   39269.053927           3\n",
       "3     48.082192                     11                        9  ...              81.79   42771.499200           1\n",
       "4     26.484018                     13                       25  ...              77.16   35509.228515           2\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['Severity','Accident_ID','Accident_Type_Code','Adverse_Weather_Metric'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the Label Encoder object which will encode the target severities to numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset for training and testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsOneClassifier (DecisionTreeClassifier) --  0.93\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "one = OneVsOneClassifier(dtc)\n",
    "one.fit(x_train,y_train)\n",
    "predictions = one.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('OneVsOneClassifier (DecisionTreeClassifier) -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier (DecisionTreeClassifier) --  0.9183333333333333\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "onevsrest = OneVsRestClassifier(dtc)\n",
    "onevsrest.fit(x_train,y_train)\n",
    "predictions = onevsrest.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('OneVsRestClassifier (DecisionTreeClassifier) -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier --  0.451\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(x_train,y_train)\n",
    "predictions = ada.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('AdaBoostClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier --  0.9346666666666666\n"
     ]
    }
   ],
   "source": [
    "dtc  = DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "predictions = dtc.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('DecisionTreeClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier --  0.601\n"
     ]
    }
   ],
   "source": [
    "etc  = ExtraTreeClassifier()\n",
    "etc.fit(x_train,y_train)\n",
    "predictions = etc.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('ExtraTreeClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier --  0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patilo\\jupyter_practice\\ml_practice\\ml_sandbox\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc  = RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "predictions = rfc.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('RandomForestClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier --  0.95\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier()\n",
    "bag.fit(x_train,y_train)\n",
    "predictions = bag.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('BaggingClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier --  0.8973333333333333\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(x_train,y_train)\n",
    "predictions = gbc.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('GradientBoostingClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsOneClassifier (BaggingClassifier) --  0.9453333333333334\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier()\n",
    "one = OneVsOneClassifier(bag)\n",
    "one.fit(x_train,y_train)\n",
    "predictions = one.predict(x_test)\n",
    "acc = accuracy_score(y_test,predictions)\n",
    "print('OneVsOneClassifier (BaggingClassifier) -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier --  0.8613333333333333\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "predictions = xgb.predict(x_test)\n",
    "acc = accuracy_score(y_test,prediction)\n",
    "print('XGBClassifier -- ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6d3e1a0669c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'XGBClassifier -- '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patilo\\jupyter_practice\\ml_practice\\ml_sandbox\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patilo\\jupyter_practice\\ml_practice\\ml_sandbox\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_id = test_data['Accident_ID']\n",
    "test_data = test_data.drop(columns=['Accident_ID','Accident_Type_Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = dtc.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categories = label_encode.inverse_transform(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'Accident_ID':activity_id,'Severity':test_categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('Prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy - 83.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
