{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the 3 columns ( keyword + location + text ) - filling the NAN by a blank or ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['text'] = training_data['keyword'].fillna('') + training_data['location'].fillna('')  \\\n",
    "                        + training_data['text'].fillna('')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = training_data.drop(columns=['id','keyword','location'],axis=1)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning step involves tokenizing, removing the stopwords and removing non-alphanumeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    tokens = text.split()\n",
    "    no_stopwords = [x for x in tokens if x not in stop_words]\n",
    "    no_nonalphanum = [x.lower() for x in no_stopwords if x.isalnum()]\n",
    "    return ' '.join(no_nonalphanum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>our deeds reason may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>all residents asked notified no evacuation she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>people receive evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>just got sent photo ruby smoke pours school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0              our deeds reason may allah forgive us       1\n",
       "1                   forest fire near la ronge canada       1\n",
       "2  all residents asked notified no evacuation she...       1\n",
       "3        people receive evacuation orders california       1\n",
       "4        just got sent photo ruby smoke pours school       1"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['text'] = training_data['text'].apply(clean_data)\n",
    "print(training_data.shape)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>heard different stay safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>forest fire spot geese fleeing across i cannot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>apocalypse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>typhoon soudelor kills 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                   just happened terrible car crash\n",
       "1                          heard different stay safe\n",
       "2  forest fire spot geese fleeing across i cannot...\n",
       "3                                         apocalypse\n",
       "4             typhoon soudelor kills 28 china taiwan"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_id = test_data['id']\n",
    "test_data['text'] = test_data['keyword'].fillna('') + test_data['location'].fillna('')  \\\n",
    "                        + test_data['text'].fillna('')\n",
    "test_data = test_data.drop(columns=['id','keyword','location'],axis=1)\n",
    "test_data['text'] = test_data['text'].apply(clean_data)\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876,)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "combined_data = combined_data.append(training_data,ignore_index=True,sort=False)\n",
    "combined_data = combined_data.append(test_data,ignore_index=True,sort=False)\n",
    "combined_data = combined_data.text\n",
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(training_data.text,training_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using nltk tokenizer to tokenize and convert text to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = training_data.text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(combined_data)\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(x_train)\n",
    "max_length = max([len(s.split()) for s in train_docs])\n",
    "x_train = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with a L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 26, 100)           2058100   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 19, 32)            25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,093,013\n",
      "Trainable params: 2,093,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patilo\\jupyter_practice\\ml_practice\\ml_sandbox\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5709 samples, validate on 1904 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 1.2943 - accuracy: 0.6322 - val_loss: 0.5561 - val_accuracy: 0.7553\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.4169 - accuracy: 0.8341 - val_loss: 0.5208 - val_accuracy: 0.7652\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.2158 - accuracy: 0.9294 - val_loss: 0.6054 - val_accuracy: 0.7621\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.1180 - accuracy: 0.9714 - val_loss: 0.7020 - val_accuracy: 0.7442\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.0864 - accuracy: 0.9799 - val_loss: 0.7772 - val_accuracy: 0.7463\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.0671 - accuracy: 0.9828 - val_loss: 0.8314 - val_accuracy: 0.7589\n",
      "Epoch 7/10\n",
      " - 8s - loss: 0.0586 - accuracy: 0.9835 - val_loss: 0.8441 - val_accuracy: 0.7453\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.0535 - accuracy: 0.9849 - val_loss: 0.7686 - val_accuracy: 0.7468\n",
      "Epoch 9/10\n",
      " - 8s - loss: 0.0481 - accuracy: 0.9858 - val_loss: 0.8039 - val_accuracy: 0.7453\n",
      "Epoch 10/10\n",
      " - 7s - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.8599 - val_accuracy: 0.7442\n",
      "Test Accuracy: 74.422270\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, verbose=2, validation_data=(x_test,y_test))\n",
    "# evaluate\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7442226890756303"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(x_test)\n",
    "accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = tokenizer.texts_to_sequences(test_data.text)\n",
    "test_data = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "prediction = model.predict_classes(test_data)\n",
    "prediction = prediction.reshape(-1,1)\n",
    "predictions = pd.DataFrame()\n",
    "for i,j in zip(test_id,prediction):\n",
    "    new = pd.DataFrame({'id':i,'target':j})\n",
    "    predictions = predictions.append(new,ignore_index=True)\n",
    "predictions.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy :---\n",
    "#####                - Local Accuracy : 74.42 (over split training data)\n",
    "#####                - Online Accuracy : 74.94 (After fitting over all training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
